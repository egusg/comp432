{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1EmgYqHv7xdhUpkrNL5eVMwF054__MGWq","timestamp":1712020208838}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","pycharm":{"stem_cell":{"cell_type":"raw","source":[],"metadata":{"collapsed":false}}}},"cells":[{"cell_type":"markdown","source":["# Replication of SpeechBrain-MOABB experimental results"],"metadata":{"collapsed":false,"id":"RbYkEFVi7bYr"}},{"cell_type":"markdown","source":["## **Prerequisites**\n"],"metadata":{"id":"7NPeJ1F5iYZy"}},{"cell_type":"markdown","source":["### Install moabb"],"metadata":{"id":"NFceIdhsidim"}},{"cell_type":"code","source":["%%capture\n","!pip install moabb"],"metadata":{"id":"SbrSTKaPRsLi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Install braindecode and skorch"],"metadata":{"id":"n19dNEYS7_tv"}},{"cell_type":"code","source":["%%capture\n","!pip install braindecode\n","!pip install skorch"],"metadata":{"id":"SGVd6oA68DKK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Defining MOABB pipelines, evaluation scheme and dataset to use**\n","Here, we set up MOABB functionalities for running a benchmark on BNCI2014-001 dataset (also known as 'BCI IV2a' dataset).\n","See a similar MOABB tutorial available at http://moabb.neurotechx.com/docs/auto_tutorials/tutorial_3_benchmarking_multiple_pipelines.html#sphx-glr-auto-tutorials-tutorial-3-benchmarking-multiple-pipelines-py.\n","\n","The pipelines adopted are the ones provided by MOABB at: https://github.com/NeuroTechX/moabb/tree/develop/pipelines.\n","Here, a cross-session evaluation scheme was adopted (i.e., leave-one-session-out cross-validation).\n","\n"],"metadata":{"id":"DZm34Ku-iifp"}},{"cell_type":"code","source":["import warnings\n","import moabb\n","import mne\n","import os\n","import numpy as np\n","from scipy.stats import sem\n","from moabb.pipelines.utils import create_pipeline_from_config\n","import yaml\n","from moabb.datasets import BNCI2014_001\n","from moabb.evaluations import CrossSessionEvaluation\n","from moabb.paradigms import MotorImagery\n","import pickle\n","\n","mne.set_log_level(\"CRITICAL\")\n","moabb.set_log_level(\"info\")\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"XXM6o9CRe7HN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from collections import Counter\n","from functools import partial\n","from inspect import getmembers, isclass, isroutine\n","\n","import mne\n","from braindecode.datasets.base import BaseConcatDataset\n","from braindecode.datasets.xy import create_from_X_y\n","from numpy import unique\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from skorch.callbacks import Callback\n","from torch.nn import Module\n","\n","class BraindecodeDatasetLoaderArray(BaseEstimator, TransformerMixin):\n","    def __init__(self, sfreq, ch_names=None, drop_last_window=False, kw_args=None):\n","        self.sfreq = sfreq\n","        self.ch_names = ch_names\n","        self.drop_last_window = drop_last_window\n","        self.kw_args = kw_args\n","\n","    def fit(self, X, y=None):\n","        self.y = y\n","        return self\n","\n","    def transform(self, X, y=None):\n","        if y is None:\n","            y = self.y\n","        dataset = create_from_X_y(\n","            X=X,\n","            y=y,\n","            window_size_samples=X.shape[2],\n","            window_stride_samples=X.shape[2],\n","            drop_last_window=self.drop_last_window,\n","            ch_names=self.ch_names,\n","            sfreq=self.sfreq,\n","        )\n","\n","        return dataset\n","\n","    def __sklearn_is_fitted__(self):\n","        \"\"\"Return True since Transformer is stateless.\"\"\"\n","        return True"],"metadata":{"id":"zv9JPPmWdHlH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import mne\n","import seaborn as sns\n","import torch\n","from braindecode import EEGClassifier\n","from braindecode.models import EEGNetv4, EEGInception, ShallowFBCSPNet, Deep4Net\n","from sklearn.pipeline import Pipeline\n","from skorch.callbacks import EarlyStopping, EpochScoring\n","from skorch.dataset import ValidSplit\n","from moabb.datasets import BNCI2014_001\n","from moabb.evaluations import CrossSessionEvaluation\n","from moabb.paradigms import MotorImagery\n","from moabb.pipelines.features import Resampler_Epoch\n","from moabb.utils import setup_seed\n","\n","mne.set_log_level(False)\n","\n","# Print Information PyTorch\n","print(f\"Torch Version: {torch.__version__}\")\n","\n","# Set up GPU if it is there\n","cuda = torch.cuda.is_available()\n","device = \"cuda\" if cuda else \"cpu\"\n","print(\"GPU is\", \"AVAILABLE\" if cuda else \"NOT AVAILABLE\")\n","\n","# Set random seed to be able to reproduce results\n","seed = 42\n","setup_seed(seed)\n","\n","# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","# Hyperparameter\n","LEARNING_RATE = 0.0001\n","WEIGHT_DECAY = 0\n","BATCH_SIZE = 64\n","SEED = 42\n","VERBOSE = 1\n","EPOCH = 1000\n","PATIENCE = 300\n","\n","model = EEGNetv4(n_chans=22,n_outputs=4,n_times=4*125)\n","if device=='cuda':\n","    model = model.cuda()\n","clf = EEGClassifier(\n","    module=model,\n","    criterion=torch.nn.CrossEntropyLoss,\n","    optimizer=torch.optim.Adam,\n","    optimizer__lr=LEARNING_RATE,\n","    batch_size=BATCH_SIZE,\n","    max_epochs=EPOCH,\n","    train_split=ValidSplit(0.2, random_state=seed),\n","    device=device,\n","    callbacks=[\n","        EarlyStopping(monitor=\"valid_loss\", patience=PATIENCE),\n","        EpochScoring(\n","            scoring=\"accuracy\", on_train=True, name=\"train_acc\", lower_is_better=False\n","        ),\n","        EpochScoring(\n","            scoring=\"accuracy\", on_train=False, name=\"valid_acc\", lower_is_better=False\n","        ),\n","\n","    ],\n","    verbose=0,  # Not printing the results for each epoch\n",")\n","\n","pipes = {}\n","pipes[\"EEGNetV4\"] = Pipeline([\n","    ('convert', moabb.pipelines.features.Convert_Epoch_Array()),\n","    ('scaler', moabb.pipelines.features.StandardScaler_Epoch()),\n","    (\"Braindecode_dataset\", BraindecodeDatasetLoaderArray(sfreq=125)),\n","     (\"EEGNetv4\", clf)])\n","\n","dataset = BNCI2014_001()\n","paradigm = MotorImagery(n_classes=4, tmin=0, tmax=4, fmin=4, fmax=40, resample=125) # no resampling, using @250 Hz\n","evaluation = CrossSessionEvaluation(\n","    paradigm=paradigm,\n","    datasets=dataset,\n","    suffix=\"braindecode_example\",\n","    hdf5_path='/content',\n","    overwrite=True,\n","    return_epochs=True,\n",")\n","\n","results_eegnet = evaluation.process(pipes)\n","results_eegnet.to_csv('/content/benchmark_bnci2014001_network.csv', sep=',')"],"metadata":{"id":"9yrhidcb-cpz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ML pipelines with tuned hyper-parameters\n","\n","tssvm_grid= \"\"\"\n","name: Tangent Space SVM Grid\n","\n","paradigms:\n","  - LeftRightImagery\n","  - MotorImagery\n","\n","citations:\n","  - https://doi.org/10.1016/j.neucom.2012.12.039\n","\n","pipeline:\n","  - name: Covariances\n","    from: pyriemann.estimation\n","    parameters:\n","      estimator: oas\n","\n","  - name: TangentSpace\n","    from: pyriemann.tangentspace\n","    parameters:\n","      metric: \"riemann\"\n","\n","  - name: SVC\n","    from: sklearn.svm\n","    parameters:\n","      kernel: \"linear\"\n","\n","param_grid:\n","  svc__C:\n","    - 0.5\n","    - 1\n","    - 1.5\n","  svc__kernel:\n","    - \"rbf\"\n","    - \"linear\"\n","\"\"\"\n","f = open('/content/tssvm_grid.yaml', \"w\")\n","f.write(tssvm_grid)\n","f.close()\n","\n","# ML pipelines with fixed hyper-parameters\n","csp_lda = \"\"\"\n","name: CSP + LDA\n","\n","paradigms:\n","  - LeftRightImagery\n","  - MotorImagery\n","\n","citations:\n","  - https://doi.org/10.1007/BF01129656\n","  - https://doi.org/10.1109/MSP.2008.4408441\n","\n","pipeline:\n","  - name: Covariances\n","    from: pyriemann.estimation\n","    parameters:\n","      estimator: oas\n","\n","  - name: CSP\n","    from: pyriemann.spatialfilters\n","    parameters:\n","      nfilter: 6\n","\n","  - name: LinearDiscriminantAnalysis\n","    from: sklearn.discriminant_analysis\n","    parameters:\n","      solver: svd\n","\"\"\"\n","\n","f = open('/content/csp_lda.yaml', \"w\")\n","f.write(csp_lda)\n","f.close()\n","\n","fcmdm= \"\"\"\n","name: FgMDM\n","\n","paradigms:\n","  - LeftRightImagery\n","  - MotorImagery\n","\n","citations:\n","  - https://doi.org/10.1007/978-3-642-15995-4_78\n","\n","pipeline:\n","  - name: Covariances\n","    from: pyriemann.estimation\n","    parameters:\n","      estimator: oas\n","\n","  - name: FgMDM\n","    from: pyriemann.classification\n","    parameters:\n","      metric: \"riemann\"\n","\"\"\"\n","f = open('/content/fcmdm.yaml', \"w\")\n","f.write(fcmdm)\n","f.close()\n","\n","mdm=\"\"\"\n","name: MDM\n","\n","paradigms:\n","  - LeftRightImagery\n","  - MotorImagery\n","\n","citations:\n","  - https://doi.org/10.1109/TBME.2011.2172210\n","\n","pipeline:\n","  - name: Covariances\n","    from: pyriemann.estimation\n","    parameters:\n","      estimator: oas\n","\n","  - name: MDM\n","    from: pyriemann.classification\n","    parameters:\n","      metric: \"riemann\"\n","\"\"\"\n","f = open('/content/mdm.yaml', \"w\")\n","f.write(mdm)\n","f.close()\n","\n","tslr=\"\"\"\n","name: Tangent Space LR\n","\n","paradigms:\n","  - LeftRightImagery\n","  - MotorImagery\n","\n","citations:\n","  - https://doi.org/10.1016/j.neucom.2012.12.039\n","\n","pipeline:\n","  - name: Covariances\n","    from: pyriemann.estimation\n","    parameters:\n","      estimator: oas\n","\n","  - name: TangentSpace\n","    from: pyriemann.tangentspace\n","    parameters:\n","      metric: \"riemann\"\n","\n","  - name: LogisticRegression\n","    from: sklearn.linear_model\n","    parameters:\n","      C: 1.0\n","\"\"\"\n","f = open('/content/tslr.yaml', \"w\")\n","f.write(tslr)\n","f.close()\n","\n","regcsp_shlda=\"\"\"\n","name: DLCSPauto + shLDA\n","\n","paradigms:\n","  - LeftRightImagery\n","  - MotorImagery\n","\n","citations:\n","  - https://doi.org/10.1007/BF01129656\n","  - https://doi.org/10.1109/MSP.2008.4408441\n","\n","pipeline:\n","  - name: Covariances\n","    from: pyriemann.estimation\n","    parameters:\n","      estimator: oas\n","\n","  - name: CSP\n","    from: pyriemann.spatialfilters\n","    parameters:\n","      nfilter: 6\n","\n","  - name: LinearDiscriminantAnalysis\n","    from: sklearn.discriminant_analysis\n","    parameters:\n","      solver: lsqr\n","      shrinkage: auto\n","\"\"\"\n","f = open('/content/regcsp_shlda.yaml', \"w\")\n","f.write(regcsp_shlda)\n","f.close()"],"metadata":{"id":"aeRWjxOkXofK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipeline_fpaths = ['/content/tssvm_grid.yaml',\n","                   '/content/csp_lda.yaml',\n","                   '/content/fcmdm.yaml',\n","                   '/content/mdm.yaml',\n","                   '/content/tslr.yaml',\n","                   '/content/regcsp_shlda.yaml',]\n","pipeline_names = ['TS+SVM',\n","                  'CSP+LDA',\n","                  'FgMDM',\n","                  'MDM',\n","                  'TS+LR',\n","                  'regCSP+shLDA']\n","pipelines = {}\n","print('Building pipelines...')\n","for pipeline_name, pipeline_fpath in zip(pipeline_names, pipeline_fpaths):\n","    #ppl = os.path.split(pipeline_fpath)[1].split('.yaml')[0]\n","    with open(pipeline_fpath) as f:\n","        pipeline = yaml.safe_load(f)\n","    print('Including {0} pipeline'.format(pipeline_name))\n","    pipelines[pipeline_name] = create_pipeline_from_config(pipeline['pipeline'])\n"],"metadata":{"id":"XTLxDU3nYUyI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["datasets = [BNCI2014_001()]\n","paradigm = MotorImagery(n_classes=4, resample=125, tmin=0, tmax=4, fmin=4, fmax=40, )\n","evaluation = CrossSessionEvaluation(\n","    paradigm=paradigm, datasets=datasets,\n","    hdf5_path='/content',\n","    overwrite=True\n",")\n","\n","results = evaluation.process(pipelines)\n","results.to_csv('/content/benchmark_bnci2014001_ml.csv', sep=',')"],"metadata":{"id":"L8a3sBqJ8v9O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","results_ml = pd.read_csv('/content/benchmark_bnci2014001_ml.csv', sep=',')\n","results_network = pd.read_csv('/content/benchmark_bnci2014001_network.csv', sep=',')\n","\n","results = pd.concat([results_ml, results_network]).reset_index(drop=True)\n","results.to_csv('/content/benchmark_bnci2014001.csv', sep=',')"],"metadata":{"id":"qvujCls-oNAf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Extract the test set results and save results as dict**"],"metadata":{"id":"EWDeCtiIbXf4"}},{"cell_type":"code","source":["pipeline_names = list(pipelines.keys())\n","pipeline_names = sorted(pipeline_names)\n","pipeline_names += ['EEGNetV4']\n","print('Results on: \\n-dataset: {0};\\n-cross-session evaluation scheme;\\n-score function: {1}.'.format(datasets[0].code, paradigm.scoring))\n","print('#'*10)\n","results_moabb = {}\n","for pipeline_name in pipeline_names:\n","    idx_pipeline = np.where(results['pipeline'].values==pipeline_name)[0]\n","    scores = results['score'].values[idx_pipeline]\n","    print('{0}: {1} (mean value); {2} (standard error of the mean)'.format(pipeline_name,\n","                                                                           round(np.mean(scores).item(),4),\n","                                                                           round(sem(scores).item(), 4)))\n","    results_moabb[pipeline_name] = results['score'][idx_pipeline].values.reshape(\n","        np.unique(results['subject']).shape[0],\n","        np.unique(results['session']).shape[0])\n","with open('/content/results_moabb.pkl', 'wb') as handle:\n","    pickle.dump(results_moabb, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","print('#'*10)"],"metadata":{"id":"mubrBM7CU8fU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Download and unzip SpeechBrain-MOABB results**\n","\n","Now download the results obtained with SpeechBrain-MOABB using neural networks, namely EEGNet, ShallowConvNet, and EEGConformer. These networks were trained on many MOABB datasets (including also on BNCI2014-001) also searching for the optimal hyper-parameters of the entire decoding pipeline (data pre-processing, data augmentation, network architecture, and network training). See the related yaml files for the hyper-parameters and the hyper-parameter search spaces of these networks.\n","\n","You can easily replicate the obtained results by performing training and evaluation again using the yaml file contained in the tar.gz compressed archive (best_hparams.yaml file).\n","\n","Please note that the file is quite large (19 GB) and the download will take a while (<15 minutes)."],"metadata":{"id":"jhyaGWeMo_Gp"}},{"cell_type":"code","source":["# Downloading Speechbrain-MOABB results using the Dropbox file provided in the Speechbrain-MOABB repository\n","url=\"https://www.dropbox.com/sh/ux0i0suljojonmb/AABsTBpEKCTmVE784yQw-WGMa?dl=1\"\n","!wget -O /content/results_speechbrain_moabb.zip $url"],"metadata":{"id":"DJrHJzzwhOCB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# unzipping Speechbrain-MOABB results (specifically for BNCI2014-001)\n","!unzip -j /content/results_speechbrain_moabb.zip results_BNCI2014001.tar.gz -d /content\n","!mkdir /content/results_speechbrain_moabb\n","!tar -xvzf results_BNCI2014001.tar.gz -C /content/results_speechbrain_moabb"],"metadata":{"id":"i7FzhiyHmP44"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Extract the test set results and save results as dict**"],"metadata":{"id":"QFun_NoKa96i"}},{"cell_type":"code","source":["import glob\n","import pickle\n","\n","model_fnames = ['EEGNet', 'ShallowConvNet', 'EEGConformer']\n","results_speechbrain_moabb_folder = '/content/results_speechbrain_moabb'\n","def get_results_single_run(run_folder):\n","    seed_dir = glob.glob(os.path.join(run_folder, '*/'))[0]\n","    sbj_dirs = glob.glob(os.path.join(seed_dir, 'leave-one-session-out', '*/'))\n","    sbj_dirs = sorted(sbj_dirs)\n","    m = []\n","    for sbj_dir in sbj_dirs:\n","        sess_dirs = glob.glob(os.path.join(sbj_dir, '*/'))\n","        mm = []\n","        for sess_dir in sess_dirs:\n","            with open(os.path.join(sess_dir, 'test_metrics.pkl'), 'rb') as f:\n","                data = pickle.load(f)\n","            mm.append(np.array(data['acc']))\n","        m.append(mm)\n","    m = np.array(m)\n","    return m\n","results = {}\n","for model_fname in model_fnames:\n","    final_evaluation_folder = os.path.join(results_speechbrain_moabb_folder,\n","                                           'BNCI2014001',\n","                                           model_fname,\n","                                           'hopt',\n","                                           'best',)\n","    final_evaluation_folder = glob.glob(os.path.join(final_evaluation_folder, '*/'))\n","    final_evaluation_folder = sorted(final_evaluation_folder)\n","    final_evaluation_folder = final_evaluation_folder[0]\n","    print(final_evaluation_folder)\n","\n","    tmp_results = []\n","    for run in np.arange(10):\n","        run_folder = os.path.join(final_evaluation_folder, 'run{0}'.format(run+1))\n","        tmp_results.append(get_results_single_run(run_folder))\n","    tmp_results = np.array(tmp_results)\n","    print(tmp_results.shape)\n","    results[model_fname] = tmp_results\n","with open('/content/results_speechbrain_moabb.pkl', 'wb') as handle:\n","    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"],"metadata":{"id":"T_aCfwaKykPP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Replicate the statistical analysis (SpeechBrain-MOABB vs. MOABB vs. MOABB+braindecode pipelines) and the figure of the paper (Fig. 4)**"],"metadata":{"id":"DvlktE-Vauvh"}},{"cell_type":"code","source":["import numpy as np\n","import os\n","import pickle\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from scipy.stats import wilcoxon, sem\n","from statsmodels.stats.multitest import multipletests\n","import matplotlib.pyplot as plt\n","from matplotlib.patches import Patch\n","\n","SMALL_SIZE = 12\n","MEDIUM_SIZE = 14\n","BIGGER_SIZE = 14#16\n","\n","plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n","plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n","plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n","plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n","plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n","plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n","\n","with open('/content/results_moabb.pkl', 'rb') as f:\n","    results_moabb = pickle.load(f)\n","with open('/content/results_speechbrain_moabb.pkl', 'rb') as f:\n","    results_speechbrain_moabb = pickle.load(f)\n","scores = []\n","\n","target_keys_moabb = ['CSP+LDA', 'regCSP+shLDA', 'MDM', 'FgMDM', 'TS+LR', 'TS+SVM', 'EEGNetV4']\n","for key in target_keys_moabb:\n","    scores.append(np.mean(results_moabb[key], axis=-1))\n","for key in results_speechbrain_moabb.keys():\n","    scores.append(np.mean(results_speechbrain_moabb[key], axis=(0,-1)))\n","\n","means = [np.mean(s) for s in scores]\n","sems = [sem(s) for s in scores]\n","keys = target_keys_moabb + list(results_speechbrain_moabb.keys())\n","\n","fig, axs = plt.subplots(2,1, figsize=(8,11/1.25))\n","ax = axs[0]\n","vp = ax.violinplot(dataset=scores, widths=0.3,\n","                   showmeans=False, showmedians=False, showextrema=False,\n","                   )\n","for pc in vp['bodies']:\n","    pc.set_facecolor('#D43F3A')\n","    pc.set_edgecolor('black')\n","    pc.set_alpha(1)\n","    pc.set_zorder(3)\n","for pc in vp['bodies'][:len(target_keys_moabb)]:\n","    pc.set_facecolor('darkcyan')\n","    pc.set_edgecolor('black')\n","    pc.set_alpha(1)\n","    pc.set_zorder(3)\n","for pc in vp['bodies'][len(target_keys_moabb)-1:len(target_keys_moabb)]:\n","    pc.set_facecolor('darkorange')\n","    pc.set_edgecolor('black')\n","    pc.set_alpha(1)\n","    pc.set_zorder(3)\n","ax.errorbar(np.arange(len(keys))+1, means, sems, linestyle='none', marker='o',\n","            c='k', zorder=3)\n","\n","ax.set_ylim(0., 1)\n","ax.axhline(y=0.25, c='k')\n","ax.grid(axis='y', c='k', linestyle='--', zorder=1)\n","ax.set_title('Performance validation on BNCI2014-001:\\nMOABB vs. MOABB+braindecode vs. SpeechBrain-MOABB pipelines')\n","ax.set_xticks(np.arange(len(keys))+1)\n","ax.set_xticklabels(keys, rotation=30, ha='right')\n","ax.set_ylabel('Accuracy')\n","legend_elements = [\n","    Patch(facecolor='darkcyan', edgecolor='k', alpha=1, label='MOABB', hatch=\"\"),\n","    Patch(facecolor='darkorange', edgecolor='k', alpha=1, label='MOABB+braindecode', hatch=\"\"),\n","    Patch(facecolor='#D43F3A', edgecolor='k', alpha=1, label='SpeechBrain-MOABB', hatch=\"\"),\n","]\n","leg = ax.legend(handles=legend_elements,\n","                  handlelength=2,\n","                  handletextpad=0.2,\n","                  labelspacing=0,\n","                  borderpad=0.3,\n","                  borderaxespad=0.1,\n","                  columnspacing=0.5,\n","                  ncols=1,\n","                  loc=\"lower right\",\n","                  framealpha=1,\n","                  edgecolor=\"k\",\n","                  ncol=1,\n","                  )\n","\n","leg.get_frame().set_boxstyle('Round', pad=0., rounding_size=0)\n","\n","\n","ax = axs[1]\n","model_fname = 'EEGNet'\n","idx0 = [i for i,k in enumerate(keys) if k==model_fname][0]\n","diff_scores = [scores[idx0]-s for s in scores]\n","means = [np.mean(s) for s in diff_scores]\n","sems = [sem(s) for s in diff_scores]\n","vp = ax.violinplot(dataset=diff_scores, widths=0.3,\n","                   showmeans=False, showmedians=False, showextrema=False,\n","                   )\n","\n","for pc in vp['bodies']:\n","    pc.set_facecolor('#D43F3A')\n","    pc.set_edgecolor('black')\n","    pc.set_alpha(1)\n","    pc.set_zorder(3)\n","for pc in vp['bodies'][:len(target_keys_moabb)]:\n","    pc.set_facecolor('darkcyan')\n","    pc.set_edgecolor('black')\n","    pc.set_alpha(1)\n","    pc.set_zorder(3)\n","for pc in vp['bodies'][len(target_keys_moabb)-1:len(target_keys_moabb)]:\n","    pc.set_facecolor('darkorange')\n","    pc.set_edgecolor('black')\n","    pc.set_alpha(1)\n","    pc.set_zorder(3)\n","idx = np.arange(len(keys))\n","idx = np.setdiff1d(idx, [idx0])\n","\n","x = np.arange(len(keys))+1\n","ax.errorbar(x, np.array(means), np.array(sems), linestyle='none', marker='o',\n","            c='k', zorder=3)\n","ax.set_ylim(-0.1, 0.5)\n","ax.axhline(y=0., c='k')\n","ax.grid(axis='y', c='k', linestyle='--', zorder=1)\n","ax.set_xticks(np.arange(len(keys))+1)\n","ax.set_xticklabels(keys, rotation=30,ha='right')\n","ax.set_ylabel(r'$\\Delta_{acc}$ (top decoder - others)')\n","\n","d0 = np.mean(results_speechbrain_moabb[model_fname], axis=(0, -1)) # (9,)\n","pvals = []\n","conds = []\n","for pipeline_fname in target_keys_moabb:\n","    d1 = np.mean(results_moabb[pipeline_fname], axis=-1) # (9,)\n","    idx1 = [i for i,k in enumerate(keys) if k==pipeline_fname][0]\n","    print('{0} vs. {1}: difference={2}'.format(model_fname, pipeline_fname, np.mean(d0-d1)))\n","    _, p = wilcoxon(d0, d1)\n","    pvals.append(p)\n","    conds.append(idx1)\n","for pipeline_fname in results_speechbrain_moabb.keys():\n","    d1 = np.mean(results_speechbrain_moabb[pipeline_fname], axis=(0,-1)) # (9,)\n","    idx1 = [i for i,k in enumerate(keys) if k==pipeline_fname][0]\n","    if d0.mean()!=d1.mean():\n","        print('{0} vs. {1}: difference={2}'.format(model_fname, pipeline_fname, np.mean(d0-d1)))\n","        _, p = wilcoxon(d0, d1)\n","        pvals.append(p)\n","        conds.append(idx1)\n","\n","print(conds)\n","print(\"Uncorrected p-values: {0}\".format(pvals))\n","_, pvals, _, _ = multipletests(pvals, method='fdr_bh')\n","print(\"Corrected p-values for multiple tests: {0}\".format(pvals))\n","signs = []\n","for p in pvals:\n","    if p<0.001:\n","        signs.append('***')\n","    else:\n","        if p<0.01:\n","            signs.append('**')\n","        else:\n","            if p<0.05:\n","                signs.append('*')\n","            else:\n","                signs.append('')\n","for k, sign in zip(conds, signs):\n","    ax.text(x=k+1, y=.4, s=sign, ha='center', va='bottom', fontsize=12)\n","\n","fig.tight_layout()\n","fig.savefig('fig4.pdf', format='PDF', dpi=600)"],"metadata":{"id":"2Q3IZrL87Osc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check for statistical significance vs. MOABB and MOABB+braindecode for each random initialization of EEGNet SpeechBrain-MOABB (not only for the average across seeds)\n","for i in np.arange(10):\n","    d0 = np.mean(results_speechbrain_moabb[model_fname][i,...], axis=(-1, )) # (9,)\n","    pvals = []\n","    for pipeline_fname in target_keys_moabb:\n","        d1 = np.mean(results_moabb[pipeline_fname], axis=-1) # (9,)\n","        idx1 = [i for i,k in enumerate(keys) if k==pipeline_fname][0]\n","        _, p = wilcoxon(d0, d1)\n","        pvals.append(p)\n","        conds.append(idx1)\n","    for pipeline_fname in results_speechbrain_moabb.keys():\n","        d1 = np.mean(results_speechbrain_moabb[pipeline_fname][i,...], axis=(-1, )) # (9,)\n","        idx1 = [i for i,k in enumerate(keys) if k==pipeline_fname][0]\n","        if d0.mean()!=d1.mean():\n","            _, p = wilcoxon(d0, d1)\n","            pvals.append(p)\n","            conds.append(idx1)\n","    _, pvals, _, _ = multipletests(pvals, method='fdr_bh')\n","    #print(\"Corrected p-values for multiple tests: {0}\".format(pvals))\n","    print(\"random iteration no. {0} always significant vs. MOABB / MOABB+braindecode?: {1} ({2} comparisons corrected for multiple tests)\".format(\n","        i, np.all(pvals[:-2]<.05), pvals.shape[0])\n","    )"],"metadata":{"id":"Vph3ZlYLzLu8","pycharm":{"name":"#%%\n"}},"execution_count":null,"outputs":[]}]}