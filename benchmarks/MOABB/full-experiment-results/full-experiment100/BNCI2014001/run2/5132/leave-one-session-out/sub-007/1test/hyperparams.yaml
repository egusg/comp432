# Generated 2024-04-25 from:
# /content/comp432/benchmarks/MOABB/hparams/MotorImagery/BNCI2014001/EEGNetE1.yaml
# yamllint disable
seed: 5132
__set_torchseed: !apply:torch.manual_seed [5132]

# DIRECTORIES
data_folder: /content/data/BNCI2014001
                           #'/path/to/dataset'. The dataset will be automatically downloaded in this folder
cached_data_folder: /content/data
                                 #'path/to/pickled/dataset'
output_folder: /content/results/full-experiment100/BNCI2014001/run2/5132
                            #'path/to/results'

# DATASET HPARS
# Defining the MOABB dataset.
dataset: !new:moabb.datasets.BNCI2014001
save_prepared_dataset: true # set to True if you want to save the prepared dataset as a pkl file to load and use afterwards
data_iterator_name: leave-one-session-out
target_subject_idx: 6
target_session_idx: 1
events_to_load:      # all events will be loaded
original_sample_rate: 250 # Original sampling rate provided by dataset authors
sample_rate: 125 # Target sampling rate (Hz)
# band-pass filtering cut-off frequencies
fmin: 1.4
fmax: 46.4
n_classes: 4
# tmin, tmax respect to stimulus onset that define the interval attribute of the dataset class
# trial begins (0 s), cue (2 s, 1.25 s long); each trial is 6 s long
# dataset interval starts from 2
# -->tmin tmax are referred to this start value (e.g., tmin=0.5 corresponds to 2.5 s)
tmin: 0.
tmax: 3.8
# number of steps used when selecting adjacent channels from a seed channel (default at Cz)
n_steps_channel_selection: 2
T: 475
C: 17
# We here specify how to perfom test:
# - If test_with: 'last' we perform test with the latest model.
# - if test_with: 'best, we perform test with the best model (according to the metric specified in test_key)
# The variable avg_models can be used to average the parameters of the last (or best) N saved models before testing.
# This can have a regularization effect. If avg_models: 1, the last (or best) model is used directly.
test_with: last   # 'last' or 'best'
test_key: acc   # Possible opts: "loss", "f1", "auc", "acc"

# METRICS
f1: &id001 !name:sklearn.metrics.f1_score
  average: macro
acc: &id002 !name:sklearn.metrics.balanced_accuracy_score
cm: &id003 !name:sklearn.metrics.confusion_matrix
# TRAINING HPARS
metrics:
  f1: *id001
  acc: *id002
  cm: *id003
n_train_examples: 232  # it will be replaced in the train script
# checkpoints to average
avg_models: 14
number_of_epochs: 100
lr: 0.0005
# Learning rate scheduling (cyclic learning rate is used here)
max_lr: 0.0005    # Upper bound of the cycle (max value of the lr)
base_lr: 0.00000001 # Lower bound in the cycle (min value of the lr)
step_size_multiplier: 5 #from 2 to 8
step_size: &id004 !apply:round
- 72.5
lr_annealing: !new:speechbrain.nnet.schedulers.CyclicLRScheduler
  base_lr: 0.00000001
  max_lr: 0.0005
  step_size: *id004
label_smoothing: 0.0
loss: !name:speechbrain.nnet.losses.nll_loss
  label_smoothing: 0.0
optimizer: !name:torch.optim.Adam
  lr: 0.0005
epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
                                                               # epoch counter
  limit: 100
batch_size_exponent: 4
batch_size: 16
valid_ratio: 0.2

# DATA AUGMENTATION
# cutcat (disabled when min_num_segments=max_num_segments=1)
max_num_segments: 4
cutcat: &id007 !new:speechbrain.augment.time_domain.CutCat
  min_num_segments: 2
  max_num_segments: 4
# random amplitude gain between 0.5-1.5 uV (disabled when amp_delta=0.)
amp_delta: 0.3884
rand_amp: &id008 !new:speechbrain.augment.time_domain.RandAmp
  amp_low: 0.6115999999999999
  amp_high: 1.3884
# random shifts between -300 ms to 300 ms (disabled when shift_delta=0.)
shift_delta_: 1 # orion_step2: --shift_delta_~"uniform(0, 25, discrete=True)"
shift_delta: 0.01                       # 0.250 # 0.-0.25 with steps of 0.01
min_shift: &id005 !apply:math.floor
- -1.25
max_shift: &id006 !apply:math.floor
- 1.25
time_shift: &id009 !new:speechbrain.augment.freq_domain.RandomShift
  min_shift: *id005
  max_shift: *id006
  dim: 1
# injection of gaussian white noise
snr_white_low: 14.0
snr_white_delta: 8.62
snr_white_high: 22.619999999999997
add_noise_white: &id010 !new:speechbrain.augment.time_domain.AddNoise
  snr_low: 14.0
  snr_high: 22.619999999999997

repeat_augment: 1 # @orion_step1: --repeat_augment 0
augment: !new:speechbrain.augment.augmenter.Augmenter
  parallel_augment: true
  concat_original: true
  parallel_augment_fixed_bs: true
  repeat_augment: 1
  shuffle_augmentations: true
  min_augmentations: 4
  max_augmentations: 4
  augmentations: [*id007, *id008, *id009, *id010]

# DATA NORMALIZATION
dims_to_normalize: 1 # 1 (time) or 2 (EEG channels)
normalize: !name:speechbrain.processing.signal_processing.mean_std_norm
  dims: 1
# MODEL
input_shape: &id011 [null, 475, 17, null]
cnn_temporal_kernels: 9
cnn_temporal_kernelsize: 48
# depth multiplier for the spatial depthwise conv. layer
cnn_spatial_depth_multiplier: 4
cnn_spatial_max_norm: 1.  # kernel max-norm constaint of the spatial depthwise conv. layer
cnn_spatial_pool: 4
cnn_septemporal_depth_multiplier: 1  # depth multiplier for the separable temporal conv. layer
cnn_septemporal_point_kernels_ratio_: 4
cnn_septemporal_point_kernels_ratio: 1.0
## number of temporal filters in the separable temporal conv. layer
cnn_septemporal_point_kernels_: 36
cnn_septemporal_point_kernels: &id012 !apply:math.ceil
- 37.0
cnn_septemporal_kernelsize_: 16
max_cnn_spatial_pool: 4
cnn_septemporal_kernelsize: &id013 !apply:round
- 16.0
cnn_septemporal_pool: 2
cnn_pool_type: avg
dense_max_norm: 0.25  # kernel max-norm constaint of the dense layer
dropout: 0.3328
activation_type: elu

model: !new:models.EEGNetE1.EEGNet
  input_shape: *id011
  cnn_temporal_kernels: 9
  cnn_temporal_kernelsize: [48, 1]
  cnn_spatial_depth_multiplier: 4
  cnn_spatial_max_norm: 1.
  cnn_spatial_pool: [4, 1]
  cnn_septemporal_depth_multiplier: 1
  cnn_septemporal_point_kernels: *id012
  cnn_septemporal_kernelsize: [*id013, 1]
  cnn_septemporal_pool: [2, 1]
  cnn_pool_type: avg
  activation_type: elu
  dense_max_norm: 0.25
  dropout: 0.3328
  dense_n_neurons: 4
